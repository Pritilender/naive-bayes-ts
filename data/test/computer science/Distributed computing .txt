computer science
distributed computing navigation search dip research distributed computing field computer science that studies distributed distributed system software system which components located networked computers communicate and coordinate their actions passing messages the components interact with each other order achieve common three significant characteristics distributed systems concurrency lack global and independent failure examples distributed systems vary from soa based systems massively multiplayer online games peer peer applications computer program that runs distributed system called distributed program and distributed programming the process writing such there are many alternatives for the message passing including rpc like connectors and message queues important goal and challenge distributed systems location transparency distributed computing also refers the use distributed systems solve computational distributed computing problem divided into many each which solved one more which communicate with each other message contents introduction architecture parallel and distributed computing history applications examples theoretical foundations models example complexity measures other problems properties distributed systems coordinator election bully algorithm chang and roberts algorithm architectures see also notes references further reading external links introduction the word distributed terms such distributed distributed and distributed algorithm originally referred computer networks where individual computers were physically distributed within some geographical the terms are nowadays used much wider even referring autonomous processes that run the same physical computer and interact with each other message while there single definition distributed the following defining properties are commonly there are several autonomous computational each which has its own local memory the entities communicate with each other message passing this the computational entities are called computers nodes distributed system may have common such solving large computational alternatively each computer may have its own user with individual and the purpose the distributed system coordinate the use shared resources provide communication services the other typical properties distributed systems include the the system has tolerate failures individual the structure the system network network number not known the system may consist different kinds computers and network and the system may change during the execution distributed each computer has only incomplete view the each computer may know only one part the architecture client server the server architecture way dispense service from central there single server that provides and many clients that communicate with the server consume its this clients and servers have different the job respond service requests from while job use the data provided response order perform some peer peer the term peer used describe distributed systems which labor divided among all the components the all the computers send and receive and they all contribute some processing power and distributed system increases its capacity computational resources peer all components the system contribute some processing power and memory distributed parallel and distributed computing distributed systems are groups networked which have the same goal for their the terms concurrent computing parallel computing and distributed have lot and clear distinction exists between the same system may characterized both parallel and distributed the processors typical distributed system run concurrently parallel computing may seen particular tightly coupled form distributed and distributed computing may seen loosely coupled form parallel nevertheless possible roughly classify concurrent systems parallel distributed using the following parallel all processors may have access shared memory exchange information between distributed each processor has its own private memory distributed memory information exchanged passing messages between the the figure the right illustrates the difference between distributed and parallel figure schematic view typical distributed the system represented network topology which each node computer and each line connecting the nodes communication figure shows the same distributed system more each computer has its own local and information can exchanged only passing messages from one node another using the available communication figure shows parallel system which each processor has direct access shared the situation further complicated the traditional uses the terms parallel and distributed algorithm that not quite match the above definitions parallel and distributed systems see the section theoretical foundations below for more detailed nevertheless rule high performance parallel computation memory multiprocessor uses parallel algorithms while the coordination scale distributed system uses distributed history the use concurrent processes that communicate passing has its roots operating system architectures studied the the first widespread distributed systems were local area networks such ethernet which was invented the arpanet the predecessor the internet was introduced the late and arpanet mail was invented the early mail became the most successful application and probably the earliest example scale distributed application addition and its the other early worldwide computer networks included usenet and fidonet from both which were used support distributed discussion the study distributed computing became its own branch computer science the late and early the first conference the symposium principles distributed computing dates back and its european counterpart international symposium distributed computing was first held applications reasons for using distributed systems and distributed computing may the very nature application may require the use communication network that connects several for data produced one physical location and required another there are many cases which the use single computer would possible but the use distributed system beneficial for practical for may more efficient obtain the desired level performance using cluster several end comparison with single end distributed system can provide more reliability than distributed there single point failure moreover distributed system may easier expand and manage than monolithic uniprocessor ghaemi define distributed query query that selects data from databases located multiple sites and offer sql examples examples distributed systems and applications distributed computing include the telecommunication networks telephone networks and cellular networks computer networks such the internet wireless sensor networks routing algorithms network world wide web and peer peer networks massively multiplayer online games and virtual reality communities distributed databases and distributed database management systems network file systems distributed information processing systems such banking systems and airline reservation systems time process aircraft control systems industrial control systems parallel computation scientific computing including cluster computing and grid computing and various volunteer computing projects see the list distributed computing projects distributed rendering computer graphics theoretical foundations distributed algorithm models many tasks that would like automate using computer are answer would like ask question and the computer should produce theoretical computer science such tasks are called computational problems formally computational problem consists instances together with solution for each instances are questions that can and solutions are desired answers these theoretical computer science seeks understand which computational problems can solved using computer computability theory and how efficiently computational complexity theory traditionally said that problem can solved using computer can design algorithm that produces correct solution for any given such algorithm can implemented computer program that runs purpose the program reads problem instance from input performs some and produces the solution output formalisms such random access machines universal turing machines can used abstract models sequential purpose computer executing such the field concurrent and distributed computing studies similar questions the case either multiple computer that executes network interacting which computational problems can solved such network and how however not all obvious what meant solving the case concurrent distributed for what the task the algorithm and what the concurrent distributed equivalent sequential purpose the discussion below focuses the case multiple although many the issues are the same for concurrent processes running single three viewpoints are commonly all computers have access shared the algorithm designer chooses the program executed each one theoretical model the parallel random access machines that are however the classical pram model assumes synchronous access the shared model that closer the behavior world multiprocessor machines and takes into account the use machine such compare swap that asynchronous shared memory there wide body work this summary which can found the the algorithm designer chooses the structure the well the program executed each models such boolean circuits and sorting networks are boolean circuit can seen computer each gate computer that runs extremely simple computer similarly sorting network can seen computer each comparator the algorithm designer only chooses the computer all computers run the same the system must work correctly regardless the structure the commonly used model graph with one finite state machine per the case distributed computational problems are typically related often the graph that describes the structure the computer network the problem this illustrated the following example consider the computational problem finding coloring given graph different fields might take the following the graph encoded and the string given input the computer program finds coloring the encodes the coloring and outputs the again the graph encoded however multiple computers can access the same string each computer might focus one part the graph and produce coloring for that the main focus performance computation that exploits the processing power multiple computers the graph the structure the computer there one computer for each node and one communication link for each edge initially each computer only knows about its immediate neighbors the graph the computers must exchange messages with each other discover more about the structure each computer must produce its own color the main focus coordinating the operation arbitrary distributed while the field parallel algorithms has different focus than the field distributed there lot interaction between the two for the cole vishkin algorithm for graph coloring was originally presented parallel but the same technique can also used directly distributed moreover parallel algorithm can implemented either parallel system using shared distributed system using message the traditional boundary between parallel and distributed algorithms choose suitable network run any given does not lie the same place the boundary between parallel and distributed systems shared memory message complexity measures parallel yet another resource addition time and space the number indeed often there off between the running time and the number the problem can solved faster there are more computers running parallel see speedup decision problem can solved polylogarithmic time using polynomial number then the problem said the class the class can defined equally well using the pram formalism boolean circuits pram machines can simulate boolean circuits efficiently and vice the analysis distributed more attention usually paid communication operations than computational perhaps the simplest model distributed computing synchronous system where all nodes operate lockstep during each communication round all nodes parallel receive the latest messages from their perform arbitrary local and send new messages their such central complexity measure the number synchronous communication rounds required complete the this complexity measure closely related the diameter the let the diameter the the one any computable problem can solved trivially synchronous distributed system approximately communication simply gather all information one location rounds solve the and inform each node about the solution rounds the other the running time the algorithm much smaller than communication then the nodes the network must produce their output without having the possibility obtain information about distant parts the other the nodes must make globally consistent decisions based information that available their local neighbourhood many distributed algorithms are known with the running time much smaller than rounds and understanding which problems can solved such algorithms one the central research questions the other commonly used measures are the total number bits transmitted the network communication complexity other problems traditional computational problems take the perspective that ask computer distributed processes the question for and then produces answer and however there are also problems where not want the system ever examples such problems include the dining philosophers problem and other similar mutual exclusion problems these the distributed system supposed continuously coordinate the use shared resources that conflicts deadlocks occur there are also fundamental challenges that are unique distributed the first example challenges that are related fault tolerance examples related problems include consensus problems byzantine fault tolerance and self stabilisation lot research also focused understanding the asynchronous nature distributed synchronizers can used run synchronous algorithms asynchronous logical clocks provide causal happened before ordering clock synchronization algorithms provide globally consistent physical time properties distributed systems far the focus has been designing distributed system that solves given complementary research problem studying the properties given distributed the halting problem analogous example from the field centralised are given computer program and the task decide whether halts runs the halting problem undecidable the general and naturally understanding the behaviour computer network least hard understanding the behaviour one however there are many interesting special cases that are possible reason about the behaviour network state one example telling whether given network interacting asynchronous and finite state machines can reach this problem pspace complete but not likely that there efficient parallel algorithm that solves the problem the case large coordinator election has been suggested that leader election merged into this discuss proposed since march coordinator election sometimes called leader election the process designating single process the organizer some task distributed among several computers before the task all network nodes are either unaware which node will serve the coordinator the unable communicate with the current after coordinator election algorithm has been however each node throughout the network recognizes unique node the task the network nodes communicate among themselves order decide which them will get into the coordinator state for they need some method order break the symmetry among for each node has unique and comparable then the nodes can compare their and decide that the node with the highest identity the the definition this problem often attributed who formalized method create new token token ring network which the token has been coordinator election algorithms are designed economical terms total bytes transmitted and the algorithm suggested humblet and spira for general undirected graphs has had strong impact the design distributed algorithms and won the dijkstra prize for influential paper distributed many other algorithms were suggested for different kind network graphs such undirected unidirectional complete grids directed euler and general method that decouples the issue the graph family from the design the coordinator election algorithm was suggested kutten and order perform distributed systems employ the concept the coordinator election problem choose process from among group processes different processors distributed system act the central several central coordinator election algorithms bully algorithm when using the bully algorithm any process sends message the current there response within given time the process tries elect itself chang and roberts algorithm the chang and roberts algorithm ring based election algorithm used find process with the largest unique identification number architectures various hardware and software architectures are used for distributed lower necessary interconnect multiple cpus with some sort regardless whether that network printed onto circuit board made loosely coupled devices and higher necessary interconnect processes running those cpus with some sort communication system distributed programming typically falls into one several basic architectures client server tier architecture tier architecture distributed objects loose coupling tight coupling client server smart client code contacts the server for data then formats and displays the input the client committed back the server when represents permanent tier architecture three tier systems move the client intelligence middle tier that stateless clients can this simplifies application most web applications are tier architecture tier refers typically web applications which further forward their requests other enterprise this type application the one most responsible for the success application servers highly coupled refers typically cluster machines that closely work running shared process the task subdivided parts that are made individually each one and then put back together make the final peer peer architecture where there special machine machines that provide service manage the network instead all responsibilities are uniformly divided among all known peers can serve both clients and space based refers infrastructure that creates the illusion one single data are transparently replicated according application decoupling space and reference another basic aspect distributed computing architecture the method communicating and coordinating work among concurrent through various message passing processes may communicate directly with one typically master slave relationship alternatively architecture can enable distributed computing done without any form direct inter process communication utilizing shared database see also this section may need reorganization comply with layout guidelines please help editing the article make improvements the overall march boinc code mobility decentralized computing distributed algorithmic mechanism design distributed cache distributed operating system edsger dijkstra prize distributed computing home grid computing jungle computing layered queueing network library oriented architecture loa list distributed computing conferences list distributed computing projects list important publications parallel and distributed computing parallel distributed processing parallel programming model oriented architecture soa volunteer computing 