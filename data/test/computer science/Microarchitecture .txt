computer science	microarchitecture navigation search list computer system manufacturers taxonomy instruction number operands this article needs additional citations for verification please help improve this article adding citations reliable sources unsourced material may challenged and january intel core electronics engineering and computer engineering microarchitecture sometimes abbreviated arch also called computer organization the way given instruction set architecture implemented given isa may implemented with different implementations may vary due different goals given design due shifts computer architecture the combination microarchitecture and instruction set contents relation instruction set architecture aspects microarchitecture microarchitectural concepts instruction cycle increasing execution speed instruction set choice instruction pipelining cache branch prediction superscalar out order execution register renaming multiprocessing and multithreading see also references further reading relation instruction set architecture the isa roughly the same the programming model processor seen assembly language programmer compiler the isa includes the execution processor registers address and data formats among other the microarchitecture includes the constituent parts the processor and how these interconnect and interoperate implement the the microarchitecture machine usually represented more less diagrams that describe the interconnections the various microarchitectural elements the which may everything from single gates and complete arithmetic logic units and even larger these diagrams generally separate the datapath where data and the control path which can said steer the the person designing system usually draws the specific microarchitecture kind data flow diagram like block diagram the microarchitecture diagram shows microarchitectural elements such the arithmetic and logic unit and the register file single schematic typically the diagram connects those elements with arrows and thick lines and thin lines distinguish between state buses which require three state buffer for each device that drives the unidirectional buses always driven single such the way the address bus simpler computers always driven the memory address register and individual control very simple computers have single data bus organization they have single three state bus the diagram more complex computers usually shows multiple state which help the machine more operations each microarchitectural element turn represented schematic describing the interconnections logic gates used implement each logic gate turn represented circuit diagram describing the connections the transistors used implement some particular logic family machines with different microarchitectures may have the same instruction set and thus capable executing the same new microarchitectures circuitry along with advances semiconductor are what allows newer generations processors achieve higher performance while using the same single microarchitecture could execute several different isas with only minor changes the microcode aspects microarchitecture intel the pipelined datapath the most commonly used datapath design microarchitecture this technique used most modern microcontrollers and dsps the pipelined architecture allows multiple instructions overlap much like assembly the pipeline includes several different stages which are fundamental microarchitecture some these stages include instruction instruction execute and write some architectures include other stages such memory the design pipelines one the central microarchitectural execution units are also essential execution units include arithmetic logic units floating point units load store branch and simd these units perform the operations calculations the the choice the number execution their latency and throughput central microarchitectural design the latency throughput and connectivity memories within the system are also microarchitectural system level design decisions such whether not include peripherals such memory controllers can considered part the microarchitectural design this includes decisions the level and connectivity these unlike architectural where achieving specific performance level the main microarchitectural design pays closer attention other since microarchitecture design decisions directly affect what goes into attention must paid such issues chip cost power consumption logic complexity ease connectivity manufacturability ease debugging testability microarchitectural concepts instruction cycle instruction cycle all single chip microprocessors chip implementations run programs performing the following read instruction and decode find any associated data that needed process the instruction process the instruction write the results out the instruction cycle repeated continuously until the power turned increasing execution speed complicating this looking series steps the fact that the memory which includes caching main memory and volatile storage like hard disks where the program instructions and data has always been slower than the processor step often introduces lengthy cpu delay while the data arrives over the computer bus considerable amount research has been put into designs that avoid these delays much over the central goal was execute more instructions thus increasing the effective execution speed these efforts introduced complicated logic and circuit initially these techniques could only implemented expensive mainframes supercomputers due the amount circuitry needed for these semiconductor manufacturing more and more these techniques could implemented single semiconductor see moore law instruction set choice instruction sets have shifted over the from originally very simple sometimes very complex various recent load store architectures vliw and epic types have been architectures that are dealing with data parallelism include simd and vectors some labels used denote classes cpu architectures are not particularly especially the cisc many early designs retroactively denoted cisc are fact significantly simpler than modern risc processors several however the choice instruction set architecture may greatly affect the complexity implementing high performance the prominent used develop the first risc was simplify instructions minimum individual semantic complexity combined with high encoding regularity and such uniform instructions were easily decoded and executed pipelined fashion and simple strategy reduce the number logic levels order reach high operating instruction memories compensated for the higher operating frequency and inherently low code density while large register sets were used factor out much the memory accesses instruction pipelining instruction pipeline one the and most techniques improve performance the use the instruction pipeline early processor designs would carry out all the steps above for one instruction before moving onto the large portions the circuitry were left idle any one for the instruction decoding circuitry would idle during execution and pipelines improve performance allowing number instructions work their way through the processor the same the same basic the processor would start decode step new instruction while the last one was waiting for this would allow four instructions one making the processor look four times although any one instruction takes just long complete there are still four the cpu whole retires instructions much risc make pipelines smaller and much easier construct cleanly separating each stage the instruction process and making them take the same amount time one the processor whole operates assembly line fashion with instructions coming one side and results out the due the reduced complexity the classic risc pipeline the pipelined core and instruction cache could placed the same size die that would otherwise fit the core alone cisc this was the real reason that risc was early designs like the sparc and mips often ran over times fast intel and motorola cisc solutions the same clock speed and pipelines are means limited risc the line vax implementation vax was heavily pipelined slightly predating the first commercial mips and sparc most modern cpus even embedded are now and microcoded cpus with pipelining are seen only the most constrained embedded large cisc from the vax the modern pentium and are implemented with both microcode and improvements pipelining and caching are the two major microarchitectural advances that have enabled processor performance keep pace with the circuit technology which they are cache cpu cache was not long before improvements chip manufacturing allowed for even more circuitry placed the and designers started looking for ways use one the most common was add increasing amount cache memory cache simply very fast memory that can accessed few cycles opposed many needed talk main the cpu includes cache controller which automates reading and writing from the the data already the cache simply appears whereas not the processor stalled while the cache controller reads risc designs started adding cache the late often only this number grew over and typical cpus now have least while more powerful cpus come with even organized multiple levels memory hierarchy generally more cache means more due reduced caches and pipelines were perfect match for each previously make much sense build pipeline that could run faster than the access latency chip using chip cache memory meant that pipeline could run the speed the cache access much smaller length this allowed the operating frequencies processors increase much faster rate than that chip branch prediction branch predictor one barrier achieving higher performance through level parallelism stems from pipeline stalls and flushes due normally whether conditional branch will taken known until late the pipeline conditional branches depend results coming from from the time that the instruction decoder has figured out that has encountered conditional branch instruction the time that the deciding register value can read the pipeline needs stalled for several not and the branch the pipeline needs clock speeds increase the depth the pipeline increases with and some modern processors may have stages every fifth instruction executed without any that high amount techniques such branch prediction and speculative execution are used lessen these branch branch prediction where the hardware makes educated guesses whether particular branch will reality one side the other the branch will called much more often than the modern designs have rather complex statistical prediction which watch the results past branches predict the future with greater the guess allows the hardware prefetch instructions without waiting for the register speculative execution further enhancement which the code along the predicted path not just prefetched but also executed before known whether the branch should taken this can yield better performance when the guess with the risk huge penalty when the guess bad because instructions need superscalar superscalar even with all the added complexity and gates needed support the concepts outlined improvements semiconductor manufacturing soon allowed even more logic gates the outline above the processor processes parts single instruction computer programs could executed faster multiple instructions were processed this what superscalar processors replicating functional units such the replication functional units was only made possible when the die area issue processor longer stretched the limits what could reliably the late superscalar designs started enter the market modern designs common find two load one store many instructions have results two more integer math two more floating point and often simd unit some the instruction issue logic grows complexity reading huge list instructions from memory and handing them off the different execution units that are idle that the results are then collected and ordered the out order execution out order execution the addition caches reduces the frequency duration stalls due waiting for data fetched from the memory but does not get rid these stalls early designs cache miss would force the cache controller stall the processor and course there may some other instruction the program whose data available the cache that out order execution allows that ready instruction processed while older instruction waits the then orders the results make appear that everything happened the programmed this technique also used avoid other operand dependency such instruction awaiting result from long latency point operation other cycle register renaming register renaming register renaming refers technique used avoid unnecessary serialized execution program instructions because the reuse the same registers those suppose have two groups instruction that will use the same register one set instructions executed first leave the register the other but the other set assigned different similar both sets instructions can executed parallel multiprocessing and multithreading multiprocessing multithreading computer computer architects have become stymied the growing mismatch cpu operating frequencies and dram access none the techniques that exploited level parallelism within one program could make for the long stalls that occurred when data had fetched from main additionally the large transistor counts and high operating frequencies needed for the more advanced ilp techniques required power dissipation levels that could longer cheaply for these newer generations computers have started exploit higher levels parallelism that exist outside single program program thread this trend sometimes known throughput computing this idea originated the mainframe market where online transaction processing emphasized not just the execution speed one but the capacity deal with massive numbers with based applications such network routing and site serving greatly increasing the last the computer industry has emphasized capacity and throughput one technique how this parallelism achieved through multiprocessing systems computer systems with multiple once reserved for end mainframes and supercomputers small scale multiprocessors servers have become commonplace for the small business for large large scale multiprocessors are even personal computers with multiple cpus have appeared since the with further transistor size reductions made available with semiconductor technology multicore cpus have appeared where multiple cpus are implemented the same silicon initially used chips targeting embedded where simpler and smaller cpus would allow multiple instantiations fit one piece semiconductor technology allowed dual end desktop cpus cmp chips manufactured some such sun microsystems ultrasparc have reverted simpler designs order fit more processors one piece another technique that has become more popular recently multithreading when the processor has fetch data from slow system instead stalling for the data the processor switches another program program thread which ready though this does not speed particular increases the overall system throughput reducing the time the cpu conceptually multithreading equivalent context switch the operating system the difference that multithreaded cpu can thread switch one cpu cycle instead the hundreds thousands cpu cycles context switch normally this achieved replicating the state hardware such the register file and program counter for each active further enhancement simultaneous multithreading this technique allows superscalar cpus execute instructions from different threads simultaneously the same see also microarchitectures list amd cpu microarchitectures list intel cpu microarchitectures microprocessor microcontroller digital signal processor cpu design hardware description language hardware architecture harvard architecture von neumann architecture core datapath dataflow architecture scale integration vhdl verilog stream processing instruction level parallelism 