computer science
compiler navigation search compiler compile compilation please help improve discuss these issues the talk page this article has unclear citation style the references used may made clearer with different consistent style citation footnoting external linking january this article includes list references but its sources remain unclear because has insufficient inline citations please help improve this article introducing more precise january program execution runtime system runtime library executable interpreter virtual machine source code object code bytecode machine code common language runtime java virtual machine compiler computer program set that transforms source code written programming language the source into another computer language the target often having binary form known object code the most common reason for wanting transform source code create executable program the name compiler primarily used for programs that translate source code from high level programming language lower level language assembly language machine code the compiled program can run computer whose cpu operating system different from the one which the compiler the compiler known cross compiler program that translates from low level language higher level one decompiler program that translates between level languages usually called source source compiler language rewriter usually program that translates the form expressions without change more compilers are sometimes called translators compiler likely perform many all the following lexical analysis preprocessing parsing semantic analysis syntax directed translation code generation and code optimization program faults caused incorrect compiler behavior can very difficult track down and work therefore compiler implementors invest significant effort ensure compiler correctness the term compiler compiler sometimes used refer parser generator tool often used help create the lexer and parser contents history compilers education compilation structure compiler compiler output compiled versus interpreted languages hardware compilation compiler construction one pass versus pass compilers front end back end compiler correctness related techniques international conferences and organizations see also notes references external links history history compiler construction software for early computers was primarily written assembly higher level programming languages were not invented until the benefits being able reuse software different kinds cpus started become significantly greater than the costs writing the limited memory capacity early computers led substantial technical challenges when the first compilers were being towards the end the machine independent programming languages were first subsequently several experimental compilers were the first compiler was written grace hopper for the programming language the functioned more loader linker than the modern notion the first autocode and its compiler were developed alick glennie for the mark computer the university manchester and considered some the first compiled programming the fortran team led john backus ibm generally credited having introduced the first complete compiler cobol was early language compiled multiple many application domains the idea using higher level language quickly caught because the expanding functionality supported newer programming languages and the increasing complexity computer compilers have become more early compilers were written assembly the first self hosting compiler capable compiling its own source code level language was created for lisp tim hart and mike levin mit since the has become common practice implement compiler the language although both pascal and have been popular choices for implementation building hosting compiler bootstrapping problem the first such compiler for language must compiled either hand compiler written different hart and lisp compiled running the compiler interpreter compilers education compiler construction and compiler optimization are taught universities and schools part computer science curriculum such courses are usually supplemented with the implementation compiler for educational programming language documented example niklaus wirth compiler which wirth used teach compiler construction the spite its the compiler introduced several influential concepts the program development stepwise refinement also the title paper the use recursive descent parser the use ebnf specify the syntax language code generator producing portable code the use diagrams the formal description the bootstrapping problem compilation this section does not cite any references sources please help improve this section adding citations reliable sources unsourced material may challenged and removed may compilers enabled the development programs that are before the development the first level the machine dependent assembly language was widely while assembly language produces more abstraction than machine code the same just with machine has modified rewritten the program executed different computer hardware architecture with the advent level programming languages that followed such and basic programmers could write independent source compiler translates the level source programs into target programs machine languages for the specific once the target program the user can execute the structure compiler compilers bridge source programs level languages with the underlying compiler verifies code generates efficient object performs time and formats the output according assembler and linker conventions compiler consists the front end verifies syntax and and generates intermediate representation the source code for processing the performs type checking collecting type generates errors and useful aspects the front end include lexical syntax and semantic the middle end performs including removal useless unreachable discovery and propagation constant relocation computation less frequently executed place out specialization computation based the generates another for the the back end generates the assembly performing register allocation assigns processor registers for the program variables where optimizes target code utilization the hardware figuring out how keep parallel execution units busy filling delay slots although most algorithms for optimization are heuristic techniques are compiler output this section does not cite any references sources please help improve this section adding citations reliable sources unsourced material may challenged and removed may one classification compilers the platform which their generated code this known the target native hosted compiler one which output intended directly run the same type computer and operating system that the compiler itself runs the output cross compiler designed run different cross compilers are often used when developing software for embedded systems that are not intended support software development the output compiler that produces code for virtual machine may may not executed the same platform the compiler that produced for this reason such compilers are not usually classified native cross the lower level language that the target compiler may itself high level programming language often viewed some sort portable can also the target language cfront the original compiler for used target the created such compiler usually not intended read and maintained indent style and pretty intermediate code are some features turn into good target code with directives can generated support debugging the original compiled versus interpreted languages higher level programming languages usually appear with type translation either designed compiled language interpreted language however practice there rarely anything about language that requires exclusively compiled exclusively although possible design languages that rely interpretation run the categorization usually reflects the most popular widespread implementations language for basic sometimes called interpreted and compiled despite the existence basic compilers and interpretation does not replace compilation only hides from the user and makes even though interpreter can itself directly executed program needed somewhere the bottom the stack see machine language modern trends toward just time compilation and bytecode interpretation times blur the traditional categorizations compilers and some language specifications spell out that implementations must include compilation for common lisp however there nothing inherent the definition common lisp that stops from being other languages have features that are very easy implement but make writing compiler much for apl snobol and many scripting languages allow programs construct arbitrary source code runtime with regular string and then execute that code passing special evaluation implement these features compiled programs must usually shipped with runtime library that includes version the compiler hardware compilation the output some compilers may target computer hardware very low for example field programmable gate array structured application specific integrated circuit such compilers are said hardware compilers synthesis tools because the source code they compile effectively controls the final configuration the hardware and how the output the compilation not instructions that are executed sequence only interconnection transistors lookup for xst the xilinx synthesis tool used for configuring similar tools are available from synplicity synopsys and other compiler construction this section does not cite any references sources please help improve this section adding citations reliable sources unsourced material may challenged and removed september compiler construction the early the approach taken compiler design used directly affected the complexity the the experience the designing and the resources compiler for relatively simple language written one person might monolithic piece when the source language large and and high quality output the design may split into number relatively independent having separate phases means development can parceled into small parts and given different also becomes much easier replace single phase improved insert new phases later additional the division the compilation processes into phases was championed the production quality compiler project carnegie mellon university this project introduced the terms front end middle end and back end all but the smallest compilers have more than two however these phases are usually regarded being part the front end the back the point which these two ends meet open the front end generally considered where syntactic and semantic processing takes along with translation lower level representation than source the middle end usually designed perform optimizations form other than the source code machine this source machine code independence intended enable generic optimizations shared between versions the compiler supporting different languages and target the back end takes the output from the may perform more transformations and optimizations that are for particular then generates code for particular processor and this end approach makes possible combine front ends for different languages with back ends for different cpus practical examples this approach are the gnu compiler collection llvm and the amsterdam compiler kit which have multiple shared analysis and multiple one pass versus pass compilers classifying compilers number passes has its background the hardware resource limitations compiling involves performing lots work and early computers did not have enough memory contain one program that did all this compilers were split into smaller programs which each made pass over the source some representation performing some the required analysis and the ability compile single pass has classically been seen benefit because simplifies the job writing compiler and pass compilers generally perform compilations faster than multi pass compilers thus partly driven the resource limitations early many early languages were specifically designed that they could compiled single pass pascal some cases the design language feature may require compiler perform more than one pass over the for consider declaration appearing line the source which affects the translation statement appearing line this the first pass needs gather information about declarations appearing after statements that they with the actual translation happening during subsequent the disadvantage compiling single pass that not possible perform many the sophisticated optimizations needed generate high quality can difficult count exactly how many passes optimizing compiler for different phases optimization may analyse one expression many times but only analyse another expression splitting compiler into small programs technique used researchers interested producing provably correct proving the correctness set small programs often requires less effort than proving the correctness single equivalent while the typical pass compiler outputs machine code from its final there are several other source source compiler type compiler that takes high level language its input and outputs high level for automatic parallelizing compiler will frequently take high level language program input and then transform the code and annotate with parallel code annotations openmp language constructs fortran statements stage compiler that compiles assembly language theoretical like some prolog implementations this prolog machine also known the warren abstract machine bytecode compilers for java python and many more are also subtype just time compiler used smalltalk and java and also microsoft common intermediate language applications are delivered which compiled native machine code just prior front end lexer parser tokens identifier reserved word number literal operator syntax tree regular free grammar for the compiler frontend analyzes the source code build internal representation the called the intermediate representation also manages the symbol table data structure mapping each symbol the source code associated information such type and while the frontend can single monolithic function scannerless parser more commonly implemented and analyzed several which may execute sequentially this particularly done for good modularity and separation concerns most commonly today this done three lexing parsing and semantic lexing and parsing comprise the syntactic analysis word syntax and phrase respectively and simple cases these modules the lexer and can automatically generated from grammar for the though more complex cases these require manual modification writing the lexical grammar and phrase grammar are usually context free grammars which simplifies analysis with sensitivity handled the semantic analysis the semantic analysis phase generally more complex and written but can partially fully automated using attribute grammars these phases themselves can further broken down lexing scanning and parsing first building concrete syntax tree parse and then transforming into abstract syntax tree syntax some cases additional phases are notably line reconstruction and preprocessing but these are detailed list possible phases line reconstruction languages which strop their keywords allow arbitrary spaces within identifiers require phase before which converts the input character sequence canonical form ready for the the top down recursive descent table driven parsers used the typically read the source one character time and did not require separate tokenizing atlas autocode and imp and some implementations algol and coral are examples stropped languages which compilers would have line reconstruction phase lexical analysis breaks the source code text into small pieces called tokens each token single atomic unit the for instance keyword identifier symbol name the token syntax typically regular language finite state automaton constructed from regular expression can used recognize this phase also called lexing and the software doing lexical analysis called lexical analyzer this may not separate step can combined with the parsing step scannerless parsing which case parsing done the character not the token preprocessing some require preprocessing phase which supports macro substitution and conditional typically the preprocessing phase occurs before syntactic semantic the case the preprocessor manipulates lexical tokens rather than syntactic however some languages such scheme support macro substitutions based syntactic syntax analysis involves parsing the token sequence identify the syntactic structure the this phase typically builds parse tree which replaces the linear sequence tokens with tree structure built according the rules formal grammar which define the the parse tree often augmented and transformed later phases the semantic analysis the phase which the compiler adds semantic information the parse tree and builds the symbol this phase performs semantic checks such type checking checking for type object binding associating variable and function references with their definite assignment requiring all local variables initialized before rejecting incorrect programs issuing semantic analysis usually requires complete parse meaning that this phase logically follows the parsing phase and logically precedes the code generation phase though often possible fold multiple phases into one pass over the code compiler back end the term back end sometimes confused with code generator because the overlapped functionality generating assembly some literature uses middle end distinguish the generic analysis and optimization phases the back end from the dependent code the main phases the back end include the analysis this the gathering program information from the intermediate representation derived from the typical analyses are data flow analysis build use define chains dependence analysis alias analysis pointer analysis escape analysis etc accurate analysis the basis for any compiler the call graph and control flow graph are usually also built during the analysis optimization the intermediate language representation transformed into functionally equivalent but faster forms popular optimizations are inline expansion dead code elimination constant propagation loop transformation register allocation and even automatic parallelization code generation the transformed intermediate language translated into the output usually the native machine language the this involves resource and storage such deciding which variables fit into registers and memory and the selection and scheduling appropriate machine instructions along with their associated addressing modes see also sethi ullman algorithm debug data may also need generated facilitate debugging compiler analysis the prerequisite for any compiler and they tightly work for dependence analysis crucial for loop transformation the scope compiler analysis and optimizations vary from small basic block the function even over the whole program interprocedural optimization obviously compiler can potentially better job using broader but that broad view not large scope analysis and optimizations are very costly terms compilation time and memory this especially true for interprocedural analysis and interprocedural analysis and optimizations are common modern commercial compilers from ibm sgi intel microsoft and sun microsystems the open source gcc was criticized for long time for lacking powerful interprocedural but changing this another open source compiler with full analysis and optimization infrastructure open which used many organizations for research and commercial due the extra time and space needed for compiler analysis and some compilers skip them users have use compilation options explicitly tell the compiler which optimizations should compiler correctness compiler correctness compiler correctness the branch software engineering that deals with trying show that compiler behaves according its language specification techniques include developing the compiler using formal methods and using rigorous testing often called compiler existing related techniques has been suggested that translator merged into this discuss proposed since july assembly language type level language and program that compiles more commonly known assembler with the inverse program known disassembler program that translates from low level language higher level one decompiler program that translates between level languages usually called language source source translator language language rewriter the last term usually applied translations that not involve change program that translates into object code format that not supported the compilation machine called cross compiler and commonly used prepare code for embedded international conferences and organizations number conferences the field programming languages present advances compiler construction one their main acm sigplan supports number including programming language design and implementation principles programming languages object oriented systems languages and applications international conference functional programming the european joint conferences theory and practice software etaps sponsors the international conference compiler with papers from both the academic and industrial asian symposium programming languages and systems organized the asian association for foundation software see also this see also section may contain excessive number suggestions please ensure that only the most relevant suggestions are given and that they are not red links and consider integrating suggestions into the article july book compiler construction abstract interpretation attribute grammar binary recompiler parsing byzantine fault tolerance compile and loader compile farm list compilers list important publications computer compilers metacompilation overhead code semantics encoding transcompiler 