computer science
computer performance navigation search computer performance characterized the amount useful work accomplished computer system computer network compared the time and resources depending the good computer performance may involve one more the short response time for given piece work high throughput rate processing low utilization computing resource high availability the computing system application fast highly data compression and decompression high bandwidth short data transmission time contents technical and technical definitions aspect software quality performance engineering application performance engineering aspects performance availability response time processing speed channel capacity latency bandwidth throughput relative efficiency scalability power consumption performance per watt compression ratio size and weight environmental impact benchmarks software performance testing profiling performance performance tuning perceived performance performance equation see also references technical and technical definitions the performance any computer system can evaluated technical using one more the metrics listed this way the performance can compared relative other systems the same system after changes defined absolute for fulfilling contractual obligation whilst the above definition relates technical the following definition given arnold allen would useful for technical the word performance computer performance means the same thing that performance means other that means how well the computer doing the work supposed aspect software quality computer software performance particularly software application response aspect software quality that important human computer interactions performance engineering performance engineering within systems encompasses the set skills activities practices tools and deliverables applied every phase the systems development life cycle which ensures that solution will implemented and operationally supported meet the performance requirements defined for the performance engineering continuously deals with offs between types occasionally cpu designer can find way make cpu with better overall performance improving one the aspects performance presented below without sacrificing the performance other for building the cpu out faster however sometimes pushing one type performance extreme leads cpu with worse overall because other important aspects were sacrificed get one looking for the speed see the megahertz myth application performance engineering application performance engineering application performance engineering specific methodology within performance engineering designed meet the challenges associated with application performance increasingly distributed cloud and terrestrial includes the skills activities practices tools and deliverables applied every phase the application lifecycle that ensure application will implemented and operationally supported meet functional performance aspects performance computer performance metrics things include availability response time channel capacity latency completion time service time bandwidth throughput relative efficiency scalability performance per watt compression ratio instruction path length and speed cpu benchmarks are availability availability availability system typically measured factor its reliability reliability does availability that less downtime availability system may also increased the strategy focusing increasing testability maintainability and not improving maintainability generally easier than maintainability estimates repair are also generally more however because the uncertainties the reliability estimates are most cases very likely dominate the availability prediction problem even while maintainability levels are very response time response time response time the total amount time takes respond request for that service can any unit work from simple disk loading complex web page the response time the sum three service time how long takes the work requested wait time how long the request has wait for requests queued ahead before gets run transmission time how long takes move the request the computer doing the work and the response back the requestor processing speed instructions per second flops most consumers pick computer architecture normally intel architecture able run large base pre compiled being relatively uninformed computer some them pick particular cpu based operating frequency see megahertz myth some system designers building parallel computers pick cpus based the speed per channel capacity channel capacity channel capacity the tightest upper bound the rate information that can reliably transmitted over communications channel the noisy channel coding theorem the channel capacity given channel the limiting information rate units information per unit that can achieved with arbitrarily small error information theory developed claude shannon during world war defines the notion channel capacity and provides mathematical model which one can compute the key result states that the capacity the defined given the maximum the mutual information between the input and output the where the maximization with respect the input latency latency latency time delay between the cause and the effect some physical change the system being latency result the limited velocity with which any physical interaction can take this velocity always lower equal speed therefore every physical system that has spatial dimensions different from zero will experience some sort the precise definition latency depends the system being observed and the nature the lower limit latency determined the medium being used for reliable way communication latency limits the maximum rate that information can there often limit the amount information that any one the field machine perceptible latency delay between what the user commands and when the computer provides the has strong effect user satisfaction and computers run sets instructions called operating the execution the process can postponed other processes are also the operating system can schedule when perform the action that the process for suppose process commands that computer voltage output set low and rate the operating system may choose adjust the scheduling each transition low based internal the latency the delay between the process instruction commanding the transition and the hardware actually transitioning the voltage from high low low system designers building real time computing systems want guarantee case that easier when the cpu has low interrupt latency and when has deterministic bandwidth bandwidth computer bandwidth measurement rate available consumed data communication resources expressed bits per second multiples kbit mbit gbit etc bandwidth sometimes defines the net bit rate peak bit information physical layer useful bit channel the maximum throughput logical physical communication path digital communication for bandwidth tests measure the maximum throughput computer the reason for this usage that according the maximum data rate physical communication link proportional its bandwidth which sometimes called frequency spectral signal bandwidth analog throughput throughput communication throughput essentially synonymous digital bandwidth wireless networks cellular systems the system spectral efficiency area bit site the maximum system throughput aggregate divided the analog bandwidth and some measure the system coverage integrated often block data flow diagram has single input and single and operate discrete packets examples such blocks are fft modules binary multipliers because the units throughput are the reciprocal the unit for propagation delay which seconds per seconds per throughput can used relate computational device performing dedicated function such asic embedded processor communications simplifying system relative efficiency relative efficiency scalability scalability power consumption the amount electricity used the this becomes especially important for systems with limited power sources such batteries human performance per watt performance per watt system designers building parallel computers such google hardware pick cpus based their speed per watt because the cost powering the cpu outweighs the cost the cpu compression ratio data compression size and weight this important performance feature mobile from the smart phones you keep your pocket the portable embedded systems environmental impact green computing the effect computer computers the during manufacturing and recycling well during measurements are taken with the objectives reducing reducing hazardous and minimizing ecological footprint benchmarks benchmark because there are many programs test cpu all aspects benchmarks were the most famous benchmarks are the specint and specfp benchmarks developed standard performance evaluation corporation and the consumermark benchmark developed the embedded microprocessor benchmark consortium eembc software performance testing software performance testing software performance testing general testing performed determine how system performs terms responsiveness and stability under particular can also serve measure validate verify other quality attributes the such reliability and resource performance testing subset performance emerging computer science practice which strives build performance into the design and architecture profiling performance profiling computer software engineering profiling program software form dynamic program analysis that for the space time complexity program the usage particular instructions frequency and duration function the most common use profiling information aid program optimization profiling achieved instrumenting either the program source code its binary executable form using tool called profiler code profiler number different techniques may used such statistical instrumented and simulation performance tuning performance tuning performance tuning the improvement system performance this typically computer but the same methods can applied economic bureaucracies other complex the motivation for such activity called performance which can real most systems will respond increased load with some degree decreasing ability accept higher load called scalability and modifying system handle higher load synonymous performance systematic tuning follows these assess the problem and establish numeric values that categorize acceptable measure the performance the system before identify the part the system that critical for improving the this called the bottleneck modify that part the system remove the measure the performance the system after the modification makes the performance adopt the modification makes the performance put back the way perceived performance perceived performance perceived computer refers how quickly software feature appears perform its the concept applies mainly user acceptance the amount time application takes start file not made faster showing startup screen see splash file progress dialog however satisfies some human appears faster the user well providing visual cue let them know the system handling their most increasing real performance increases perceived but when real performance cannot increased due physical techniques can used increase perceived performance the cost marginally decreasing real performance equation the total amount time required execute particular benchmark program where the terms execute the number instructions actually executed the instruction path length the code density the instruction set strongly affects the value can either determined exactly using instruction set simulator itself based partly estimated actual frequency distribution input variables and examining generated machine code from hll compiler cannot determined from the number lines hll source not affected other processes running the same the significant point here that hardware normally does not keep track least make easily value for executed the value can therefore only accurately determined instruction set which rarely the clock frequency cycles per the average cycles per instruction for this the average instructions per cycle for this even one different compiler the same compiler with different compiler optimization switches can change and the benchmark executes faster the new compiler can improve without making the other but often there off between for use few complicated instructions that take long time use instructions that execute very although takes more them execute the cpu designer often required implement particular instruction set and cannot change sometimes designer focuses improving performance making significant improvements with techniques such deeper pipelines and faster while not sacrificing too much leading speed demon cpu sometimes designer focuses improving performance making significant improvements cpi with techniques such out order execution superscalar cpus larger caches with improved hit improved branch speculative execution etc while not sacrificing too much clock leading brainiac cpu for given instruction set and therefore fixed and semiconductor the maximum thread performance requires balance between brainiac techniques and speedracer see also algorithmic efficiency computer performance orders magnitude network performance optimization computer giga updates per second measure how frequently the ram can updated complete instruction set 